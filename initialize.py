"""
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€æœ€åˆã®ç”»é¢èª­ã¿è¾¼ã¿æ™‚ã«ã®ã¿å®Ÿè¡Œã•ã‚Œã‚‹åˆæœŸåŒ–å‡¦ç†ãŒè¨˜è¿°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
"""

# èª²é¡Œ4ã®ãŸã‚
from langchain_community.document_loaders import PyMuPDFLoader

class PageAwarePDFLoader(PyMuPDFLoader):
    def load(self):
        docs = super().load()
        for i, doc in enumerate(docs):
            if "page" not in doc.metadata:
                doc.metadata["page"] = i
        return docs


############################################################
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
############################################################
import os
import logging
from logging.handlers import TimedRotatingFileHandler
from uuid import uuid4
import sys
import unicodedata
from dotenv import load_dotenv
import streamlit as st
from docx import Document
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
# from langchain_community.vectorstores import Chromaã€€steamlitã§ä½¿ãˆãªã„ã®ã§ä¸‹è¨˜ã‚³ãƒ¼ãƒ‰ã«æ›¸ãæ›ãˆ
from langchain_community.vectorstores import FAISS #FAISSã«æ›¸ãæ›ãˆãŸã‚³ãƒ¼ãƒ‰â€™
import constants as ct


############################################################
# è¨­å®šé–¢é€£
############################################################
# ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾©ã—ãŸç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()


############################################################
# é–¢æ•°å®šç¾©
############################################################

def initialize():
    """
    ç”»é¢èª­ã¿è¾¼ã¿æ™‚ã«å®Ÿè¡Œã™ã‚‹åˆæœŸåŒ–å‡¦ç†
    """
    # åˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”¨æ„
    initialize_session_state()
    # ãƒ­ã‚°å‡ºåŠ›ç”¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
    initialize_session_id()
    # ãƒ­ã‚°å‡ºåŠ›ã®è¨­å®š
    initialize_logger()
    # RAGã®Retrieverã‚’ä½œæˆ
    initialize_retriever()


def initialize_logger():
    """
    ãƒ­ã‚°å‡ºåŠ›ã®è¨­å®š
    """
    # æŒ‡å®šã®ãƒ­ã‚°ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚Œã°èª­ã¿è¾¼ã¿ã€å­˜åœ¨ã—ãªã‘ã‚Œã°æ–°è¦ä½œæˆ
    os.makedirs(ct.LOG_DIR_PATH, exist_ok=True)
    
    # å¼•æ•°ã«æŒ‡å®šã—ãŸåå‰ã®ãƒ­ã‚¬ãƒ¼ï¼ˆãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã‚’å–å¾—
    # å†åº¦åˆ¥ã®ç®‡æ‰€ã§å‘¼ã³å‡ºã—ãŸå ´åˆã€ã™ã§ã«åŒã˜åå‰ã®ãƒ­ã‚¬ãƒ¼ãŒå­˜åœ¨ã—ã¦ã„ã‚Œã°èª­ã¿è¾¼ã‚€
    logger = logging.getLogger(ct.LOGGER_NAME)

    # ã™ã§ã«ãƒ­ã‚¬ãƒ¼ã«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ­ã‚°ã®å‡ºåŠ›å…ˆã‚’åˆ¶å¾¡ã™ã‚‹ã‚‚ã®ï¼‰ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€åŒã˜ãƒ­ã‚°å‡ºåŠ›ãŒè¤‡æ•°å›è¡Œã‚ã‚Œãªã„ã‚ˆã†å‡¦ç†ã‚’ä¸­æ–­ã™ã‚‹
    if logger.hasHandlers():
        return

    # 1æ—¥å˜ä½ã§ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€åˆ‡ã‚Šæ›¿ãˆã‚‹è¨­å®š
    log_handler = TimedRotatingFileHandler(
        os.path.join(ct.LOG_DIR_PATH, ct.LOG_FILE),
        when="D",
        encoding="utf8"
    )
    # å‡ºåŠ›ã™ã‚‹ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®šç¾©
    # - ã€Œlevelnameã€: ãƒ­ã‚°ã®é‡è¦åº¦ï¼ˆINFO, WARNING, ERRORãªã©ï¼‰
    # - ã€Œasctimeã€: ãƒ­ã‚°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆã„ã¤è¨˜éŒ²ã•ã‚ŒãŸã‹ï¼‰
    # - ã€Œlinenoã€: ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œç•ªå·
    # - ã€ŒfuncNameã€: ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚ŒãŸé–¢æ•°å
    # - ã€Œsession_idã€: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆèª°ã®ã‚¢ãƒ—ãƒªæ“ä½œã‹åˆ†ã‹ã‚‹ã‚ˆã†ã«ï¼‰
    # - ã€Œmessageã€: ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    formatter = logging.Formatter(
        f"[%(levelname)s] %(asctime)s line %(lineno)s, in %(funcName)s, session_id={st.session_state.session_id}: %(message)s"
    )

    # å®šç¾©ã—ãŸãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®é©ç”¨
    log_handler.setFormatter(formatter)

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ã€ŒINFOã€ã«è¨­å®š
    logger.setLevel(logging.INFO)

    # ä½œæˆã—ãŸãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ­ã‚°å‡ºåŠ›å…ˆã‚’åˆ¶å¾¡ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã‚’ã€
    # ãƒ­ã‚¬ãƒ¼ï¼ˆãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®Ÿéš›ã«ç”Ÿæˆã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã«è¿½åŠ ã—ã¦ãƒ­ã‚°å‡ºåŠ›ã®æœ€çµ‚è¨­å®š
    logger.addHandler(log_handler)


def initialize_session_id():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä½œæˆ
    """
    if "session_id" not in st.session_state:
        # ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼‰ã‚’ã€ãƒ­ã‚°å‡ºåŠ›ç”¨ã«ä½œæˆ
        st.session_state.session_id = uuid4().hex

def initialize_retriever( chunk_size=500, top_k=20, chunk_overlap=50,): #èª²é¡Œ2
    """
    ç”»é¢èª­ã¿è¾¼ã¿æ™‚ã«RAGã®Retrieverï¼ˆãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‹ã‚‰æ¤œç´¢ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã‚’ä½œæˆ
    """
    # ãƒ­ã‚¬ãƒ¼ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã§ã€å¾Œç¶šã®å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãªã©ãŒãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã•ã‚Œã‚‹
    logger = logging.getLogger(ct.LOGGER_NAME)

    # ã™ã§ã«RetrieverãŒä½œæˆæ¸ˆã¿ã®å ´åˆã€å¾Œç¶šã®å‡¦ç†ã‚’ä¸­æ–­
    if "retriever" in st.session_state:
        return
    
    # RAGã®å‚ç…§å…ˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿
    docs_all = load_data_sources()


    # # OSãŒWindowsã®å ´åˆã€Unicodeæ­£è¦åŒ–ã¨ã€cp932ï¼ˆWindowsç”¨ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ï¼‰ã§è¡¨ç¾ã§ããªã„æ–‡å­—ã‚’é™¤å»
    # for doc in docs_all:
    #     doc.page_content = adjust_string(doc.page_content)
    #     for key in doc.metadata:
    #         doc.metadata[key] = adjust_string(doc.metadata[key])
    
    # ã€ä¿®æ­£â‘ ã€‘OSä¾å­˜ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰èª¿æ•´ï¼ˆå…ƒã®å‡¦ç†ï¼‰ï¼‹ ãƒ¡ã‚¿æƒ…å ±ã®è£œæ­£
    for i, doc in enumerate(docs_all):
        doc.page_content = adjust_string(doc.page_content)
        for key in doc.metadata:
            doc.metadata[key] = adjust_string(doc.metadata[key])

        # ã€ä¿®æ­£â‘¡ã€‘pageãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã«è£œæ­£ã™ã‚‹
        if "page" not in doc.metadata:
            doc.metadata["page"] = 0  # â† ä»®ã«0ãƒšãƒ¼ã‚¸ã‚’è¨­å®šï¼ˆæœ¬æ¥ã¯æ­£ç¢ºãªãƒšãƒ¼ã‚¸ç•ªå·ã‚’ç¶­æŒï¼‰

        # ã€ä¿®æ­£â‘¢ã€‘sourceãŒãªã„å ´åˆã«file_pathã‹ã‚‰è£œå®Œã™ã‚‹
        if "source" not in doc.metadata and "file_path" in doc.metadata:
            doc.metadata["source"] = doc.metadata["file_path"]

# èª²é¡Œ4è¿½åŠ 
    for doc in docs_all:
        source = doc.metadata.get("source", "ä¸æ˜ãƒ•ã‚¡ã‚¤ãƒ«")
        page = doc.metadata.get("page", "ä¸æ˜ãƒšãƒ¼ã‚¸")
        doc.page_content = (
            f"ã€ã“ã®æƒ…å ±ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{source}ã€ã®{int(page)+1}ãƒšãƒ¼ã‚¸ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‘\n\n"
            f"{doc.page_content}"
        )

    # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ç”¨æ„
    embeddings = OpenAIEmbeddings()
    
    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    text_splitter = CharacterTextSplitter(
        chunk_size=chunk_size, # èª²é¡Œ2
        chunk_overlap=chunk_overlap, #
        separator="\n"
    )

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’å®Ÿæ–½
    splitted_docs = text_splitter.split_documents(docs_all)

    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ä½œæˆ
    # db = Chroma.from_documents(splitted_docs, embedding=embeddings) ä¸‹è¨˜ã«æ›¸ãæ›ãˆ
    db = FAISS.from_documents(splitted_docs, embedding=embeddings) #æ›¸ãæ›ãˆãŸå ´æ‰€

    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’æ¤œç´¢ã™ã‚‹Retrieverã®ä½œæˆ
    st.session_state.retriever = db.as_retriever(search_kwargs={"k": top_k}) #èª²é¡Œ1,2

# èª²é¡Œ4è¿½åŠ 
    print(f"âœ… ãƒãƒ£ãƒ³ã‚¯æ•°: {len(splitted_docs)}")
    for i, doc in enumerate(splitted_docs[:5]):
        print(f"{i}: chars={len(doc.page_content)}, page={doc.metadata.get('page')}, source={doc.metadata.get('source')}")


def initialize_session_state():
    """
    åˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”¨æ„
    """
    if "messages" not in st.session_state:
        # ã€Œè¡¨ç¤ºç”¨ã€ã®ä¼šè©±ãƒ­ã‚°ã‚’é †æ¬¡æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ç”¨æ„
        st.session_state.messages = []
        # ã€ŒLLMã¨ã®ã‚„ã‚Šã¨ã‚Šç”¨ã€ã®ä¼šè©±ãƒ­ã‚°ã‚’é †æ¬¡æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ç”¨æ„
        st.session_state.chat_history = []


def load_data_sources():
    """
    RAGã®å‚ç…§å…ˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿

    Returns:
        èª­ã¿è¾¼ã‚“ã é€šå¸¸ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
    """
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
    docs_all = []
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã®å®Ÿè¡Œï¼ˆæ¸¡ã—ãŸå„ãƒªã‚¹ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒæ ¼ç´ã•ã‚Œã‚‹ï¼‰
    recursive_file_check(ct.RAG_TOP_FOLDER_PATH, docs_all)

    web_docs_all = []
    # ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã¯åˆ¥ã«ã€æŒ‡å®šã®Webãƒšãƒ¼ã‚¸å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿
    # èª­ã¿è¾¼ã¿å¯¾è±¡ã®Webãƒšãƒ¼ã‚¸ä¸€è¦§ã«å¯¾ã—ã¦å‡¦ç†
    for web_url in ct.WEB_URL_LOAD_TARGETS:
        # æŒ‡å®šã®Webãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿
        loader = WebBaseLoader(web_url)
        web_docs = loader.load()
        # foræ–‡ã®å¤–ã®ãƒªã‚¹ãƒˆã«èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
        web_docs_all.extend(web_docs)
    # é€šå¸¸èª­ã¿è¾¼ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«Webãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    docs_all.extend(web_docs_all)

# é–‹ç™ºå¾Œãªã®ã§ãƒŸãƒ¥ãƒ¼ãƒˆã«
# # èª²é¡Œ4è¿½åŠ 
#     print("ğŸ“„ èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:")
#     for doc in docs_all:
#         print(f"{doc.metadata.get('source')} | page={doc.metadata.get('page')} | chars={len(doc.page_content)}")

    return docs_all


def recursive_file_check(path, docs_all):
    """
    RAGã®å‚ç…§å…ˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿

    Args:
        path: èª­ã¿è¾¼ã¿å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        docs_all: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
    """
    # ãƒ‘ã‚¹ãŒãƒ•ã‚©ãƒ«ãƒ€ã‹ã©ã†ã‹ã‚’ç¢ºèª
    if os.path.isdir(path):
        # ãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆã€ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€åã®ä¸€è¦§ã‚’å–å¾—
        files = os.listdir(path)
        # å„ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã«å¯¾ã—ã¦å‡¦ç†
        for file in files:
            # ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€åã ã‘ã§ãªãã€ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
            full_path = os.path.join(path, file)
            # ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ¸¡ã—ã€å†å¸°çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã®é–¢æ•°ã‚’å®Ÿè¡Œ
            recursive_file_check(full_path, docs_all)
    else:
        # ãƒ‘ã‚¹ãŒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        file_load(path, docs_all)


# def file_load(path, docs_all):
#     """
#     ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

#     Args:
#         path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
#         docs_all: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
#     """
#     # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—
#     file_extension = os.path.splitext(path)[1]
#     # ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ã‚’å«ã‚€ï¼‰ã‚’å–å¾—
#     file_name = os.path.basename(path)

#     # èª²é¡Œ4è¿½åŠ 
#     if file_extension == ".pdf":
#         loader = PageAwarePDFLoader(path)

#     # æƒ³å®šã—ã¦ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å ´åˆã®ã¿èª­ã¿è¾¼ã‚€
#     if file_extension in ct.SUPPORTED_EXTENSIONS:
#         # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã«åˆã£ãŸdata loaderã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
#         loader = ct.SUPPORTED_EXTENSIONS[file_extension](path)
#         docs = loader.load()
#         docs_all.extend(docs)

# èª²é¡Œ4ã®ãŸã‚ã«å·®ã—æ›¿ãˆ
def file_load(path, docs_all):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

    Args:
        path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        docs_all: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—
    file_extension = os.path.splitext(path)[1]
    # ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ã‚’å«ã‚€ï¼‰ã‚’å–å¾—
    file_name = os.path.basename(path)

    # å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if file_extension not in ct.SUPPORTED_EXTENSIONS and file_extension != ".pdf":
        return

    # èª²é¡Œ4ï¼š.pdf ã®å ´åˆã¯ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨
    if file_extension == ".pdf":
        loader = PageAwarePDFLoader(path)
    else:
        loader = ct.SUPPORTED_EXTENSIONS[file_extension](path)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    docs = loader.load()
    docs_all.extend(docs)


def adjust_string(s):
    """
    Windowsç’°å¢ƒã§RAGãŒæ­£å¸¸å‹•ä½œã™ã‚‹ã‚ˆã†èª¿æ•´
    
    Args:
        s: èª¿æ•´ã‚’è¡Œã†æ–‡å­—åˆ—
    
    Returns:
        èª¿æ•´ã‚’è¡Œã£ãŸæ–‡å­—åˆ—
    """
    # èª¿æ•´å¯¾è±¡ã¯æ–‡å­—åˆ—ã®ã¿
    if type(s) is not str:
        return s

    # OSãŒWindowsã®å ´åˆã€Unicodeæ­£è¦åŒ–ã¨ã€cp932ï¼ˆWindowsç”¨ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ï¼‰ã§è¡¨ç¾ã§ããªã„æ–‡å­—ã‚’é™¤å»
    if sys.platform.startswith("win"):
        s = unicodedata.normalize('NFC', s)
        s = s.encode("cp932", "ignore").decode("cp932")
        return s
    
    # OSãŒWindowsä»¥å¤–ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
    return s